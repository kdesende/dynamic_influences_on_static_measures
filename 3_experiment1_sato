#######################
#3. Experiment 1: SATO 
rm(list=ls())
error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
  if(length(x) != length(y) | length(y) !=length(lower) | length(lower) != length(upper))
    stop("vectors must be same length")
  arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length, ...)
}
# to source, compile and run C++ functions
library(Rcpp) 
sourceCpp("DDM_with_confidence_slow.cpp") # this will give R access to the DDM_with_confidence_slow function 
#Load code to compute metad
source('computeMetaDa.R')
#merge together two DFs with different variable names
source('fastmerge.R')
#Load the heatmap reprenseint p(correct|evt,t,x)
pcor <- as.matrix(read.table('pcor_5secs.txt',header=T)) #sigma=.1
pcorVector <- as.vector(pcor)
evUp <- seq(0,1,by=.01);

#Create a function that compares observed data to simulate data using quantile optimisation 
chi_square_optim <- function(params, observations, returnFit){
  
  #First, generate predictions:
  names(params) <- c('v','a','ter','z','ntrials','sigma','dt','t2time','vratio','add_mean','add_sd')
  predictions <- data.frame(DDM_with_confidence_slow(v=params['v'],a=params['a'],ter=params['ter'],z=params['z'],ntrials=params['ntrials'],s=params['sigma'],dt=params['dt'],t2time=params['t2time'],postdriftmod=params['vratio']))
  names(predictions) <- c('rt','resp','cor','raw_evidence2','rt2','cj')
  predictions$evidence2 <- predictions$raw_evidence2
  
  #1. Convert cj into p(correct), so first flip
  #1.1 starting point is a*z, so if you reach the upper bound evidence2 should be evidence2-z*a
  predictions$evidence2[predictions$resp==1] <- predictions$evidence2[predictions$resp==1] - params['z']*params['a']
  #if you reach the lower bound evidence2 should be evidence2+z*a 
  predictions$evidence2[predictions$resp==-1] <- (-predictions$evidence2[predictions$resp==-1]) + params['z']*params['a']
  
  #1.1 Empirical heatmap
  #match to the heatmap
  predictions$evidence2 <- predictions$evidence2*.1 #the heatmap is created using sigma=.1
  predictions$closest_evdnc2 <- match.closest(abs(predictions$evidence2),evUp)
  predictions$temprt2 <- predictions$rt2;
  predictions$temprt2[predictions$temprt2>5] <- 5 #heatmap doesn't go higher
  predictions$temprt2 <- predictions$temprt2*(dim(pcor)[1]/5) #scale with the heatmap, between 0 and 2000
  
  #pcorVector is aggregatedd per evidence row, so first accumulate up until evidence-1, and then add RT
  #sigma is scaled until it's .1, so use pcorVevector
  predictions$conft2 <- pcorVector[(predictions$closest_evdnc2-1)*dim(pcor)[1]+round(predictions$temprt2)]
  
  #correct trials where evidence2 < 0 should take the flip into account (conf = conf - 2*(conf-.5))
  predictions$conft2[predictions$resp==1&predictions$evidence2<0] <- predictions$conft2[predictions$resp==1&predictions$evidence2<0] - 2*(predictions$conft2[predictions$resp==1&predictions$evidence2<0]-.5)
  #error trials where evidence2 has < 0 should take the flip into account (note that this is ALSo <0 because i've already flipped evidence beforehand)
  predictions$conft2[predictions$resp==-1&predictions$evidence2<0] <- predictions$conft2[predictions$resp==-1&predictions$evidence2<0] - 2*(predictions$conft2[predictions$resp==-1&predictions$evidence2<0]-.5)
  
  #Use heatmap confidence instead of raw evidence
  predictions$cj <- predictions$conft2
  
  #2. Linear scaling of confidence 
  predictions$cj <- (predictions$cj + params['add_mean'])/params['add_sd']
  predictions$cj[predictions$cj<0] <- 0
  predictions$cj[predictions$cj>100] <- 100
  
  #Add a peak at 50, the proportion of which is controlled by the empirically observed peak
  P <- length(which(observations$cj==50))/length(observations$cj)
  
  sorted_cj <- sort(predictions$cj);idx_50 <- which.min(abs(sorted_cj - 50))[1]
  lower <- c(-1,-1);one_value_up <- 0
  while(length(lower)!=1){
    lower <- sorted_cj[idx_50-round((P/2)*dim(predictions)[1]) + one_value_up]
    upper <- sorted_cj[idx_50+round((P/2)*dim(predictions)[1]) + one_value_up]
    one_value_up <- one_value_up+1 #in case the data is not symmetrical around 50,this value controls for that by shifting everything up
  }
  predictions$cj[predictions$cj>=lower & predictions$cj<upper] <- 50
  
  # again, separate the predections according to the response
  c_predicted <- predictions[predictions$cor == 1,]
  e_predicted <- predictions[predictions$cor == 0,]
  
  # to make the next step easier, lets sort the predictions for correct and errors
  c_predicted_rt <- sort(c_predicted$rt)
  e_predicted_rt <- sort(e_predicted$rt)
  
  #if we're only simulating data, return the predictions
  if(returnFit==0){ 
    return(predictions[,c('rt','cor','cj')])
    
    #If we are fitting the model, now compare these predictions to the observations 
  }else{ 
    
    # First, separate the data in correct and error trials
    c_observed <- observations[observations$cor == 1,]
    e_observed <- observations[observations$cor == 0,]
    
    # Now, get the quantile RTs on the "observed data" for correct and error distributions separately (for quantiles .1, .3, .5, .7, .9)
    c_quantiles <- quantile(c_observed$rt, probs = c(.1,.3,.5,.7,.9), names = FALSE)
    e_quantiles <- quantile(e_observed$rt, probs = c(.1,.3,.5,.7,.9), names = FALSE)
    
    # to combine correct and incorrect we scale the expected interquantile probability by the proportion of correct and incorect respectively
    prop_obs_c <- dim(c_observed)[1] / dim(observations)[1]
    prop_obs_e <- dim(e_observed)[1] / dim(observations)[1]
    
    c_obs_proportion = prop_obs_c * c(.1, .2, .2, .2, .2, .1)
    e_obs_proportion = prop_obs_e * c(.1, .2, .2, .2, .2, .1)
    obs_props <- c(c_obs_proportion,e_obs_proportion)
    
    # now, get the proportion of responses that fall between the observed quantiles when applied to the predicted data (scale by N?)
    c_pred_proportion <- c(
      sum(c_predicted_rt <= c_quantiles[1]),
      sum(c_predicted_rt <= c_quantiles[2]) - sum(c_predicted_rt <= c_quantiles[1]),
      sum(c_predicted_rt <= c_quantiles[3]) - sum(c_predicted_rt <= c_quantiles[2]),
      sum(c_predicted_rt <= c_quantiles[4]) - sum(c_predicted_rt <= c_quantiles[3]),
      sum(c_predicted_rt <= c_quantiles[5]) - sum(c_predicted_rt <= c_quantiles[4]),
      sum(c_predicted_rt > c_quantiles[5])
    ) / dim(predictions)[1]
    
    e_pred_proportion <- c(
      sum(e_predicted_rt <= e_quantiles[1]),
      sum(e_predicted_rt <= e_quantiles[2]) - sum(e_predicted_rt <= e_quantiles[1]),
      sum(e_predicted_rt <= e_quantiles[3]) - sum(e_predicted_rt <= e_quantiles[2]),
      sum(e_predicted_rt <= e_quantiles[4]) - sum(e_predicted_rt <= e_quantiles[3]),
      sum(e_predicted_rt <= e_quantiles[5]) - sum(e_predicted_rt <= e_quantiles[4]),
      sum(e_predicted_rt > e_quantiles[5])
    ) / dim(predictions)[1]
    pred_props <- c(c_pred_proportion,e_pred_proportion)
    
    # avoid zeros in the the data (because of division by predictions for chi square statistic) -> set to small number
    pred_props[pred_props==0] <- .0000001
    
    # Now, do the same for confidence
    # Get the quantile Cjs on the "observed data" for correct and error distributions separately (for quantiles .1, .3, .5, .7, .9)
    c_quantiles_cj <- quantile(c_observed$cj, probs = c(.1,.3,.5,.7,.9), names = FALSE)
    e_quantiles_cj <- quantile(e_observed$cj, probs = c(.1,.3,.5,.7,.9), names = FALSE)
    
    # to make the next step easier, lets sort the predictions for correct and errors
    c_predicted_cj <- sort(c_predicted$cj)
    e_predicted_cj <- sort(e_predicted$cj)
    
    # now, get the proportion of responses that fall between the observed quantiles when applied to the predicted data (scale by N?)
    c_pred_proportion_cj <- c(
      sum(c_predicted_cj <= c_quantiles_cj[1]),
      sum(c_predicted_cj <= c_quantiles_cj[2]) - sum(c_predicted_cj <= c_quantiles_cj[1]),
      sum(c_predicted_cj <= c_quantiles_cj[3]) - sum(c_predicted_cj <= c_quantiles_cj[2]),
      sum(c_predicted_cj <= c_quantiles_cj[4]) - sum(c_predicted_cj <= c_quantiles_cj[3]),
      sum(c_predicted_cj <= c_quantiles_cj[5]) - sum(c_predicted_cj <= c_quantiles_cj[4]),
      sum(c_predicted_cj > c_quantiles_cj[5])
    ) / dim(predictions)[1]
    
    e_pred_proportion_cj <- c(
      sum(e_predicted_cj <= e_quantiles_cj[1]),
      sum(e_predicted_cj <= e_quantiles_cj[2]) - sum(e_predicted_cj <= e_quantiles_cj[1]),
      sum(e_predicted_cj <= e_quantiles_cj[3]) - sum(e_predicted_cj <= e_quantiles_cj[2]),
      sum(e_predicted_cj <= e_quantiles_cj[4]) - sum(e_predicted_cj <= e_quantiles_cj[3]),
      sum(e_predicted_cj <= e_quantiles_cj[5]) - sum(e_predicted_cj <= e_quantiles_cj[4]),
      sum(e_predicted_cj > e_quantiles_cj[5])
    ) / dim(predictions)[1]
    pred_props_cj <- c(c_pred_proportion_cj,e_pred_proportion_cj)
    
    # avoid zeros in the the data (because of division by predictions for chi square statistic) -> set to small number
    pred_props_cj[pred_props_cj==0] <- .0000001
    
    # Combine the quantiles for rts and cj
    obs_props <- c(obs_props,obs_props)
    pred_props <- c(pred_props,pred_props_cj)
    # calculate chi square
    chiSquare = sum( ( (obs_props - pred_props) ^ 2) / pred_props )
    
    #Return chiSquare
    return(chiSquare)
  }
}


data_files <- list.files(path=c("SATO experiment/Data"),pattern = "*", recursive = FALSE)
for(i in 1:length(data_files)){
  if(i == 1){ Data <- read.csv(paste0("SATO experiment/Data/",data_files[i]))
  }else{
    temp <- read.csv(paste0("SATO experiment/Data/",data_files[i]))
    Data <- fastmerge(temp,Data)
  }
}
#Rename some stuff to more useful variables
Data$sub <- Data$sona_ID
Data$coh <- Data$coherence
Data$cor <- ifelse(Data$correct=='true',1,0)
Data$rt <- Data$rt/1000
Data$cj <- Data$resp_confidence
table(Data$sub,Data$condition)
Training <- subset(Data, c(condition!="accuracy" & condition!="speed"))
Data <- subset(Data,c(condition=="accuracy" | condition=="speed"))
Data$response <- ifelse(Data$key_press==69,1,0)

#exclude negative RTs and RTs < .1
Data <- subset(Data,rt > .1)

#Exclude subjects with more then 10 training blocks
N_training_block <- with(Training,aggregate(block,by=list(sub=sub,phase=phase),max));N_training_block <- cast(N_training_block,sub~phase)
colMeans(data.frame(N_training_block[N_training_block$training_1<10&N_training_block$training_3<10,]))
N_training_block <- with(Training,aggregate(block,by=list(sub=sub),max))
plot(N_training_block$x)
Data <- subset(Data, sub != N_training_block$sub[N_training_block$x>10][1])
Data <- subset(Data, sub != N_training_block$sub[N_training_block$x>10][2])

#
subs <- unique(Data$sub);N<-length(subs)

meanerr <- with(Data,aggregate(cor,by=list(sub=sub),mean))
plot(meanerr$x)

par(mfrow=c(2,2))
at_chance <- matrix(NA,nrow=N,ncol=2)
for(i in 1:N){
  #main exp
  tempDat <- subset(Data,sub==subs[i])
  acc_block <- with(tempDat,aggregate(cor,by=list(block=block),mean))  
  at_chance[i,] <- c(subs[i], t.test(acc_block$x,mu=.5)$p.value)
  bias_block <- with(tempDat,aggregate(response,by=list(block=block),mean))  
}
Data <- subset(Data, sub!= at_chance[at_chance[,2]>.05,1][1]) #
Data <- subset(Data, sub!= at_chance[at_chance[,2]>.05,1][2]) #

#
subs <- unique(Data$sub);N<-length(subs)

#Run the model or load results if they already exist
dprime_sato <- matrix(NA,N,2);mratio_sato <- matrix(NA,N,2);bound_sato <- matrix(NA,N,2);drift_sato <- matrix(NA,N,2);ter_sato <- matrix(NA,N,2);vratio_sato <- matrix(NA,N,2);conf_rt_sato <- matrix(NA,N,2);mean_acc_sato <- matrix(NA,N,2);add_mean_sato <- matrix(NA,N,2);add_sd_sato <- matrix(NA,N,2);
for(i in 1:N){
  print(paste('Running participant',i,'from',N))
  condLab <- unique(Data$condition)
  tempAll <- subset(Data,sub==subs[i])
  for(c in 1:2){
    tempDat <- subset(tempAll,condition==condLab[c])
    conf_rt_sato[i,c] <- median(tempDat$rt_confidence/1000)
    tempDat$stim <- ifelse(tempDat$cor==tempDat$response,1,0);
    tempDat <- tempDat[,c('rt','cor','response','cj','stim')]
    mean_acc_sato[i,c] <- mean(tempDat$cor)
    tempDat$conf <- tempDat$cj
    #Load existing individual results if already exist
    if(file.exists(paste0('SATO experiment/fits/results_sub_',i,'_',condLab[c],'.Rdata'))){
      load(paste0('SATO experiment/fits/results_sub_',i,'_',condLab[c],'.Rdata'))
      par(mfrow=c(2,4)) #plot fitting over time
      plot(results$member$bestmemit[,1],ylab='drift',ylim=c(0,2),frame=F,type='l',main=paste('sub',i,'condition',condLab[c]))
      plot(results$member$bestmemit[,2],ylab='bound',ylim=c(.5,4),frame=F,type='l')
      plot(results$member$bestmemit[,3],ylab='ter',ylim=c(0,1),frame=F,type='l')
      plot(results$member$bestmemit[,9],ylab='vratio',ylim=c(0,2),frame=F,type='l')
    }else{ #if not, fit the model
      optimal_params <- DEoptim(chi_square_optim, # function to optimize
                                lower = c(0, .5, 0, .5, 5000, 1, .001, conf_rt_sato[i,c],   0, 0,  0,  0,  0,   0), # v,a,ter,z,ntrials,sigma,dt,t2time,vratio,add_mean,add_sd,peak_at_100,peak_at_50,peak_at_0
                                upper = c(3,  4, 1, .5, 5000, 1, .001, conf_rt_sato[i,c], 2.5, 3, .1,  0, .15,  0), # v,a,ter,z,ntrials,sigma,dt,t2time,vratio
                                observations = tempDat,control=c(itermax=500)) # observed data is a parameter for the ks function we pass
      results <- summary(optimal_params)
      #save individual results
      save(results, file=paste0('SATO experiment/fits/results_sub_',i,'_',condLab[c],'.Rdata'))
    }
    drift_sato[i,c] <- results$optim$bestmem[1]
    bound_sato[i,c] <- results$optim$bestmem[2]
    ter_sato[i,c] <- results$optim$bestmem[3]
    vratio_sato[i,c] <-   results$optim$bestmem[9]
    add_mean_sato[i,c] <-   results$optim$bestmem[10]
    add_sd_sato[i,c] <-   results$optim$bestmem[11]

    #divide cj into 5 bins for the meta-d
    tempDat$cj <- as.numeric(cut(tempDat$cj,5))  
    fit <- computeMetaDa(as.factor(tempDat$cj),as.factor(tempDat$stim),as.factor(tempDat$cor))
    dprime_sato[i,c] <- fit$Da
    mratio_sato[i,c] <- fit$metaDa/fit$Da
  }
}

jpeg(file="sato_results.jpg", res=600, width=400*4*(350/72), height=400*(350/72))
par(mfrow=c(1,4))
plot(colMeans(drift_sato),frame=F,cex.lab=1.5,ylim=c(0,2.5),xlim=c(.8,2.2),ylab="Drift rate",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,drift_sato[i,1:2],type='b',lty=2,col='grey',pch=19)
points(colMeans(drift_sato),type='b',lwd=5);error.bar(1:2,colMeans(drift_sato),colSds(as.matrix(drift_sato))/sqrt(N),length=0,lwd=3)
plot(colMeans(bound_sato),frame=F,cex.lab=1.5,ylim=c(.5,4),xlim=c(.8,2.2),ylab="Decision boundary",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,bound_sato[i,1:2],type='b',lty=2,col='grey',pch=19)
points(colMeans(bound_sato),type='b',lwd=5);error.bar(1:2,colMeans(bound_sato),colSds(as.matrix(bound_sato))/sqrt(N),length=0,lwd=3)
plot(colMeans(mratio_sato),frame=F,cex.lab=1.5,ylim=c(-.5,2.5),xlim=c(.8,2.2),ylab="M-ratio",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,mratio_sato[i,1:2],type='b',lty=2,col='grey',pch=19)
points(colMeans(mratio_sato),type='b',lwd=5);error.bar(1:2,colMeans(mratio_sato),colSds(as.matrix(mratio_sato))/sqrt(N),length=0,lwd=3)
plot(colMeans(vratio_sato),frame=F,cex.lab=1.5,ylim=c(0,2.5),xlim=c(.8,2.2),ylab="Post-decision drift rate",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,vratio_sato[i,1:2],type='b',lty=2,col='grey',pch=19)
points(colMeans(vratio_sato),type='b',lwd=5);error.bar(1:2,colMeans(vratio_sato),colSds(as.matrix(vratio_sato))/sqrt(N),length=0,lwd=3)
dev.off()

#stats
t.test(drift_sato[,1]-drift_sato[,2])
t.test(bound_sato[,1],bound_sato[,2],p=T)
t.test(ter_sato[,1]-ter_sato[,2])
t.test(vratio_sato[,1]-vratio_sato[,2])
t.test(add_mean_sato[,1]-add_mean_sato[,2])
t.test(add_sd_sato[,1]-add_sd_sato[,2])
t.test(mratio_sato[,1]-mratio_sato[,2])

#correlations within each condition
par(mfrow=c(1,2))
plot(mratio_sato[,1]~vratio_sato[,1],frame=F,pch=19,main="be accurate");cor.test(mratio_sato[,1],vratio_sato[,1]);abline(lm(mratio_sato[,1]~vratio_sato[,1]),lty=2)
plot(mratio_sato[,2]~vratio_sato[,2],frame=F,pch=19,main="be fast");cor.test(mratio_sato[,2],vratio_sato[,2]);abline(lm(mratio_sato[,2]~vratio_sato[,2]),lty=2)

plot(mratio_sato[,1]~bound_sato[,1],frame=F,pch=19);cor.test(mratio_sato[,1],bound_sato[,1]);abline(lm(mratio_sato[,1]~bound_sato[,1]),lty=2)
plot(mratio_sato[,2]~bound_sato[,2],frame=F,pch=19);cor.test(mratio_sato[,2],bound_sato[,2]);abline(lm(mratio_sato[,2]~bound_sato[,2]),lty=2)

#Generate model simulations
rm(Simuls);nsim <- 5000
for(i in 1:N){
  print(paste('simulating',i,'from',N))
  tempAll <- subset(Data,sub==subs[i])
  for(c in 1:2){
    tempDat <- subset(tempAll,condition==condLab[c]);tempDat$conf <- tempDat$cj
    temp <- chi_square_optim(c(drift_sato[i,c],bound_sato[i,c],ter_sato[i,c],.5,nsim,1,.001,conf_rt_sato[i,c],vratio_sato[i,c],add_mean_sato[i,c],add_sd_sato[i,c]),tempDat,0) 
    if(!exists('Simuls')){ Simuls <- cbind(temp,rep(c,nsim),rep(i,nsim))
    }else{ Simuls <- fastmerge(Simuls,cbind(temp,rep(c,nsim),rep(i,nsim)))
    }
  }
}
Simuls <- data.frame(Simuls);names(Simuls) <- c('rt','cor','cj','condition','sub')

#Average performance for behavior and model predictions
ER <- with(Data,aggregate(cor,by=list(sub=sub,condition=condition),mean));ER <- cast(ER,sub~condition)
DataCor <- subset(Data,cor==1);RT <- with(DataCor,aggregate(rt,by=list(sub=sub,condition=condition),median));RT <- cast(RT,sub~condition)
CJ <- with(Data,aggregate(cj,by=list(sub=sub,condition=condition),mean));CJ <- cast(CJ,sub~condition)

ER_sim <- with(Simuls,aggregate(cor,by=list(sub=sub,condition=condition),mean));ER_sim <- cast(ER_sim,sub~condition)
SimulsCor <- subset(Simuls,cor==1);RT_sim <- with(SimulsCor,aggregate(rt,by=list(sub=sub,condition=condition),median));RT_sim <- cast(RT_sim,sub~condition)
CJ_sim <- with(Simuls,aggregate(cj,by=list(sub=sub,condition=condition),mean));CJ_sim <- cast(CJ_sim,sub~condition)

jpeg(file="Manuscript dynamic metad/sato_behavresults.jpg", res=600, width=400*3*(350/72), height=400*(350/72))
par(mfrow=c(1,3))
plot(colMeans(ER)*100,frame=F,xlim=c(.8,2.2),cex.lab=1.5,type='n',ylim=c(50,100),ylab="Accuracy (%)",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,ER[i,2:3]*100,type='b',lty=2,col="grey",pch=19)
points(colMeans(ER)*100,type='b',lwd=5);error.bar(1:2,colMeans(ER)*100,colSds(as.matrix(ER))*100/sqrt(N),length=0,lwd=3)
points(colMeans(ER_sim)*100,pch=4,col="green",cex=2,lwd=3)

plot(colMeans(RT),frame=F,type='n',cex.lab=1.5,xlim=c(.8,2.2),ylim=range(RT),ylab="Reaction times (s)",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,RT[i,2:3],type='b',lty=2,col="grey",pch=19)
points(colMeans(RT),type='b',lwd=5);error.bar(1:2,colMeans(RT),colSds(as.matrix(RT))/sqrt(N),length=0,lwd=3)
points(colMeans(RT_sim),pch=4,col="green",cex=2,lwd=3)

plot(colMeans(CJ),frame=F,type='n',cex.lab=1.5,xlim=c(.8,2.2),ylim=range(CJ),ylab="Confidence",xlab="Instruction condition",xaxt='n');axis(1,1:2,c("Accuracy","Speed"))
for(i in 1:N) lines(1:2,CJ[i,2:3],type='b',lty=2,col="grey",pch=19)
points(colMeans(CJ),type='b',lwd=5);error.bar(1:2,colMeans(CJ),colSds(as.matrix(CJ))/sqrt(N),length=0,lwd=3)
points(colMeans(CJ_sim),pch=4,col="green",cex=2,lwd=3)
dev.off()

t.test(ER[,2],ER[,3],p=T)
t.test(RT[,2],RT[,3],p=T)
t.test(CJ[,2],CJ[,3],p=T)

#Overlay RT and confidence distributions from data and simulations
scale_speed <- (dim(Data)[1]/dim(Simuls)[1]);scale_acc <- (dim(Data)[1]/dim(Simuls)[1])

jpeg(file="sato_fit.jpg", res=600, width=600*2*(350/72), height=600*(350/72))
par(mfrow=c(2,2),mar=c(5.1,5.1,4.1,2.1))
tempC <- hist(Data$rt[Data$cor==1&Data$condition=="accuracy"],breaks=seq(0,6.2,.1),xlim=c(0,3),prob=F,col=rgb(0,1,0,.25),border="white",ylab="Frequency",xlab="Reaction times (s)",cex.lab=2, cex.main=1.5, cex.axis=1.5,main="Be accurate")
tempE <- hist(Data$rt[Data$cor==0&Data$condition=="accuracy"],breaks=seq(0,6.2,.1),prob=F,add=T,col=rgb(1,0,0,.25),border='white')
Cors <- hist(Simuls$rt[Simuls$cor==1&Simuls$condition==1],breaks=seq(0,30,.1),plot=F)
Errs <- hist(abs(Simuls$rt[Simuls$cor==0&Simuls$condition==1]),breaks=seq(0,25,.1),plot=F)
lines(rescale(Cors$counts,to=c(0,max(tempC$counts)))~Cors$mids,type='l',col='green',lwd=3)
lines(rescale(Errs$counts,to=c(0,max(tempE$counts)))~Errs$mids,type='l',col='red',lwd=3)
legend("topright",fill=c("white","white","green","red"),border=F,legend=c("Simulated corrects","Simulated errors","Empirical corrects","Empirical errors"),col=rep(c("Green","Red"),2),bty='n',lwd=c(1,1,-1,-1))
tempC <- hist(Data$rt[Data$cor==1&Data$condition=="speed"],breaks=seq(0,6.2,.1),xlim=c(0,3),prob=F,col=rgb(0,1,0,.25),border="white",ylab="Frequency",xlab="Reaction times (s)",cex.lab=2, cex.main=1.5, cex.axis=1.5,main="Be fast")
tempE <- hist(Data$rt[Data$cor==0&Data$condition=="speed"],breaks=seq(0,6.2,.1),prob=F,add=T,col=rgb(1,0,0,.25),border='white')
Cors <- hist(Simuls$rt[Simuls$cor==1&Simuls$condition==2],breaks=seq(0,20,.1),plot=F)
Errs <- hist(abs(Simuls$rt[Simuls$cor==0&Simuls$condition==2]),breaks=seq(0,20,.1),plot=F)
lines(rescale(Cors$counts,to=c(0,max(tempC$counts)))~Cors$mids,type='l',col='green',lwd=3)
lines(rescale(Errs$counts,to=c(0,max(tempE$counts)))~Errs$mids,type='l',col='red',lwd=3)
#same for confidence
tempC <- hist(Data$cj[Data$cor==1&Data$condition=="accuracy"],breaks=seq(0,100,2),xlim=c(0,100),prob=F,col=rgb(0,1,0,.25),border="white",ylab="Frequency",xlab="Confidence",cex.lab=2, cex.main=1.5, cex.axis=1.5,main="Be accurate")
tempE <- hist(Data$cj[Data$cor==0&Data$condition=="accuracy"],breaks=seq(0,100,2),prob=F,add=T,col=rgb(1,0,0,.25),border='white')
Cors <- hist(Simuls$cj[Simuls$cor==1&Simuls$condition==1],breaks=seq(0,100,2),plot=F)
Errs <- hist(abs(Simuls$cj[Simuls$cor==0&Simuls$condition==1]),breaks=seq(0,100,2),plot=F)
lines(Cors$counts*(dim(Data)[1]/dim(Simuls)[1])~Cors$mids,type='l',col='green',lwd=3)
lines(Errs$counts*(dim(Data)[1]/dim(Simuls)[1])~Errs$mids,type='l',col='red',lwd=3)
tempC <- hist(Data$cj[Data$cor==1&Data$condition=="speed"],breaks=seq(0,100,2),xlim=c(0,100),prob=F,col=rgb(0,1,0,.25),border="white",ylab="Frequency",xlab="Confidence",cex.lab=2, cex.main=1.5, cex.axis=1.5,main="Be fast")
tempE <- hist(Data$cj[Data$cor==0&Data$condition=="speed"],breaks=seq(0,100,2),prob=F,add=T,col=rgb(1,0,0,.25),border='white')
Cors <- hist(Simuls$cj[Simuls$cor==1&Simuls$condition==2],breaks=seq(0,100,2),plot=F)
Errs <- hist(abs(Simuls$cj[Simuls$cor==0&Simuls$condition==2]),breaks=seq(0,100,2),plot=F)
lines(Cors$counts*(dim(Data)[1]/dim(Simuls)[1])~Cors$mids,type='l',col='green',lwd=3)
lines(Errs$counts*(dim(Data)[1]/dim(Simuls)[1])~Errs$mids,type='l',col='red',lwd=3)
dev.off()


